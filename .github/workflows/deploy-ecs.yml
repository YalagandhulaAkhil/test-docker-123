# .github/workflows/deploy-ecs.yml
# ───────────────────────────────────────────────────────────────
# Deploys the ECS *Fargate* cluster stack.
# Reads VPC ID from the VPC stack’s outputs in S3, then
# creates/updates the ECS cluster and security group.
# ───────────────────────────────────────────────────────────────
name: Deploy ECS Cluster

on:
  push:
    paths:
      - "infra/ecs.yml"
      - ".github/workflows/deploy-ecs.yml"
      - "scripts/save-outputs.sh"
      - "scripts/read-s3-outputs.sh"
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION:        ${{ secrets.AWS_REGION }}
  VPC_STACK:         my-vpc-stack          # ← your VPC stack name
  STACK_NAME:        ecs-cluster-stack     # ← keep fixed so exports stay stable
  S3_BUCKET_NAME:    ${{ secrets.S3_BUCKET_NAME }}

jobs:
  deploy-ecs:
    runs-on: ubuntu-latest

    steps:
      # 1️⃣ Checkout repo
      - uses: actions/checkout@v4

      # 2️⃣ Configure AWS credentials via OIDC
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region:     ${{ env.AWS_REGION }}

      # 3️⃣ Read VPC ID from S3‑stored outputs
      - name: Read VPC ID from VPC stack
        run: |
          set -euo pipefail
          chmod +x scripts/read-s3-outputs.sh
          VPC_ID=$(scripts/read-s3-outputs.sh "${{ env.VPC_STACK }}" VpcId)

          if [[ -z "$VPC_ID" ]]; then
            echo "❌  Failed to obtain VpcId from ${VPC_STACK}"
            exit 1
          fi

          echo "✅  VpcId resolved: $VPC_ID"
          echo "VPC_ID=$VPC_ID" >> "$GITHUB_ENV"

      # 4️⃣ Deploy / update the ECS cluster stack
      - name: Deploy ECS cluster CloudFormation stack
        run: |
          aws cloudformation deploy \
            --stack-name ${STACK_NAME} \
            --template-file infra/ecs.yml \
            --parameter-overrides \
                ECSClusterName=html-ecs \
                VpcId=${VPC_ID} \
            --no-fail-on-empty-changeset

      # 5️⃣ Save outputs and upload to S3
      - name: Save ECS outputs.txt to S3
        run: |
          chmod +x scripts/save-outputs.sh
          S3_BUCKET_NAME=${{ env.S3_BUCKET_NAME }} \
          ./scripts/save-outputs.sh ${STACK_NAME}

      # 6️⃣ Attach outputs as GitHub artifact (optional)
      - name: Upload outputs.txt artifact
        uses: actions/upload-artifact@v4
        with:
          name: ecs-cluster-outputs
          path: infra/outputs.txt
