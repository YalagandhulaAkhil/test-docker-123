name: Deploy ECS Cluster

on:
  push:
    paths:
      - "infra/ecs.yml"
      - ".github/workflows/deploy-ecs.yml"
      - "scripts/save-outputs.sh"
      - "scripts/read-s3-outputs.sh"
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION:   ${{ secrets.AWS_REGION }}
  STACK_NAME:   ecs-cluster-stack
  VPC_STACK:    my-vpc-stack
  IAM_STACK:    my-iam-stack
  S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}

jobs:
  deploy-ecs:
    runs-on: ubuntu-latest

    steps:
    # 1 â”€ Check out code
    - uses: actions/checkout@v4

    # 2 â”€ Configure AWS credentials (OIDC)
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
        aws-region:     ${{ env.AWS_REGION }}

    # 3 â”€ Download & parse outputs
    - name: Read outputs from previous stacks
      run: |
        set -euo pipefail

        echo "ðŸ“¥ Downloading outputs.txt files"
        aws s3 cp s3://${S3_BUCKET_NAME}/${VPC_STACK}/outputs.txt vpc_outputs.txt
        aws s3 cp s3://${S3_BUCKET_NAME}/${IAM_STACK}/outputs.txt iam_outputs.txt

        echo "ðŸ” vpc_outputs.txt";  cat vpc_outputs.txt
        echo "ðŸ” iam_outputs.txt";  cat iam_outputs.txt

        # Allow optional spaces around '=' and trim whitespace
        VPC_ID=$(grep -E '^ *VpcId *=' vpc_outputs.txt | cut -d '=' -f2 | xargs)
        SUBNET1=$(grep -E '^ *PublicSubnet1Id *=' vpc_outputs.txt | cut -d '=' -f2 | xargs)
        SUBNET2=$(grep -E '^ *PublicSubnet2Id *=' vpc_outputs.txt | cut -d '=' -f2 | xargs)
        PROFILE_ARN=$(grep -E '^ *ECSInstanceProfileArn *=' iam_outputs.txt | cut -d '=' -f2 | xargs)

        for var in VPC_ID SUBNET1 SUBNET2 PROFILE_ARN; do
          if [[ -z "${!var}" ]]; then
            echo "âŒ Missing or empty value for $var"
            exit 1
          fi
        done

        echo "âœ… Extracted:"
        echo "  VPC_ID=$VPC_ID"
        echo "  SUBNET1=$SUBNET1"
        echo "  SUBNET2=$SUBNET2"
        echo "  PROFILE_ARN=$PROFILE_ARN"

        echo "VPC_ID=$VPC_ID"           >> $GITHUB_ENV
        echo "SUBNET1=$SUBNET1"         >> $GITHUB_ENV
        echo "SUBNET2=$SUBNET2"         >> $GITHUB_ENV
        echo "PROFILE_ARN=$PROFILE_ARN" >> $GITHUB_ENV

    # 4 â”€ Deploy cluster
    - name: Deploy ECS CloudFormation stack
      id: deploy
      run: |
        set -e
        SubnetCSV="${SUBNET1},${SUBNET2}"
        aws cloudformation deploy \
          --stack-name ${STACK_NAME} \
          --template-file infra/ecs.yml \
          --parameter-overrides \
              ECSClusterName=html-ecs \
              VpcId=${VPC_ID} \
              SubnetIds="${SubnetCSV}" \
              Ec2InstanceProfileArn=${PROFILE_ARN} \
              KeyName=${{ secrets.AAA }} \
          --capabilities CAPABILITY_NAMED_IAM \
          --no-fail-on-empty-changeset

    # 5 â”€ Dump events on failure
    - name: Dump CFN events on failure
      if: failure() && steps.deploy.outcome == 'failure'
      run: |
        aws cloudformation describe-stack-events \
          --stack-name ${STACK_NAME} --max-items 30 --output table

    # 6 â”€ Save ECS outputs & push to S3
    - name: Save ECS outputs to S3
      if: success()
      run: |
        chmod +x scripts/sav
