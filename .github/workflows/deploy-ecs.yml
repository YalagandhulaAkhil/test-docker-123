name: Deploy ECS Cluster (read outputs from S3)

on:
  push:
    paths:
      - "infra/ecs.yml"
      - ".github/workflows/deploy-ecs.yml"
      - "scripts/read-s3-outputs.sh"
      - "scripts/save-outputs.sh"
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION:   ${{ secrets.AWS_REGION }}
  STACK_NAME:   ecs-cluster-stack
  VPC_STACK:    my-vpc-stack
  IAM_STACK:    my-iam-stack
  S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}

jobs:
  deploy-ecs:
    runs-on: ubuntu-latest

    steps:
    # 1. Checkout
    - uses: actions/checkout@v4

    # 2. AWS creds via OIDC
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
        aws-region:     ${{ env.AWS_REGION }}

    # 3. Pull outputs from S3
    - name: Fetch stack outputs and export variables
      run: |
        set -euo pipefail
        chmod +x scripts/read-s3-outputs.sh
        export S3_BUCKET_NAME=${{ env.S3_BUCKET_NAME }}

        echo "🔹 Downloading outputs.txt files"
        for S in ${VPC_STACK} ${IAM_STACK}; do
          aws s3 cp s3://${S3_BUCKET_NAME}/${S}/outputs.txt - || echo "(missing $S)"
        done

        VPC_ID=$(scripts/read-s3-outputs.sh ${VPC_STACK} VpcId)
        SUBNET1=$(scripts/read-s3-outputs.sh ${VPC_STACK} PublicSubnet1Id)
        SUBNET2=$(scripts/read-s3-outputs.sh ${VPC_STACK} PublicSubnet2Id)
        PROFILE_ARN=$(scripts/read-s3-outputs.sh ${IAM_STACK} ECSInstanceProfileArn)

        for var in VPC_ID SUBNET1 SUBNET2 PROFILE_ARN; do
          [[ -z "${!var}" ]] && { echo "❌ Missing $var"; exit 1; }
        done

        echo "VPC_ID=$VPC_ID"           >> $GITHUB_ENV
        echo "SUBNET1=$SUBNET1"         >> $GITHUB_ENV
        echo "SUBNET2=$SUBNET2"         >> $GITHUB_ENV
        echo "PROFILE_ARN=$PROFILE_ARN" >> $GITHUB_ENV

    # 4. Deploy Cluster
    - name: Deploy ECS CloudFormation stack
      id: deploy
      run: |
        set -e
        SubnetCSV="${SUBNET1},${SUBNET2}"
        aws cloudformation deploy \
          --stack-name ${STACK_NAME} \
          --template-file infra/ecs.yml \
          --parameter-overrides \
              ECSClusterName=html-ecs \
              VpcId=${VPC_ID} \
              SubnetIds="${SubnetCSV}" \
              Ec2InstanceProfileArn=${PROFILE_ARN} \
              KeyName=${{ secrets.AAA }} \
          --capabilities CAPABILITY_NAMED_IAM \
          --no-fail-on-empty-changeset

    # 5. Dump events on failure
    - name: Dump CFN events on failure
      if: failure() && steps.deploy.outcome == 'failure'
      run: |
        aws cloudformation describe-stack-events \
          --stack-name ${STACK_NAME} --max-items 30 --output table

    # 6. Push ECS outputs to S3
    - name: Save ECS outputs and push to S3
      if: success()
      run: |
        chmod +x scripts/save-outputs.sh
        S3_BUCKET_NAME=${{ env.S3_BUCKET_NAME }} \
        ./scripts/save-outputs.sh ${STACK_NAME}

    # 7. Upload artifact
    - name: Upload outputs.txt artifact
      if: success()
      uses: actions/upload-artifact@v4
      with:
        name: ecs-outputs
        path: infra/outputs.txt
